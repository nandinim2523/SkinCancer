{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3283665-100f-44c4-a61c-8c826d60ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2557ccb2-6a33-4bed-931c-2b4ccf810ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18eea4f3-7e85-4645-a91e-93862b102191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2374 images belonging to 2 classes.\n",
      "Found 263 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# setup for data generators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "valid_gen = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc60e3a8-0892-4c86-9e2c-027517f9f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\AppData\\Local\\Temp\\ipykernel_23600\\1027193824.py:15: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_mnv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n"
     ]
    }
   ],
   "source": [
    "# model functions\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, VGG16\n",
    "\n",
    "def build_model(base_model):\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# MobileNetV2 Model\n",
    "base_mnv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_mnv2.trainable = False\n",
    "model_mnv2 = build_model(base_mnv2)\n",
    "\n",
    "# ResNet50 Model\n",
    "base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_resnet.trainable = False\n",
    "model_resnet = build_model(base_resnet)\n",
    "\n",
    "# VGG16 Model\n",
    "base_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_vgg.trainable = False\n",
    "model_vgg = build_model(base_vgg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4504f0f1-e9c0-4972-9a99-263724228dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_mnv2.save('skin_cancer_mnv2.h5')\n",
    "model_resnet.save('skin_cancer_resnet50.h5')\n",
    "model_vgg.save('skin_cancer_vgg16.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b5839d-cc4d-4293-9134-3c14e9fb7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 2s/step - accuracy: 0.7475 - loss: 0.4971 - val_accuracy: 0.5475 - val_loss: 1.1225\n",
      "Epoch 2/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 2s/step - accuracy: 0.8710 - loss: 0.2819 - val_accuracy: 0.5475 - val_loss: 1.2827\n",
      "Epoch 3/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 2s/step - accuracy: 0.8868 - loss: 0.2403 - val_accuracy: 0.5513 - val_loss: 1.7992\n",
      "Epoch 4/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 2s/step - accuracy: 0.9098 - loss: 0.1968 - val_accuracy: 0.6046 - val_loss: 0.8210\n",
      "Epoch 5/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 2s/step - accuracy: 0.9268 - loss: 0.1852 - val_accuracy: 0.7338 - val_loss: 0.6257\n",
      "Training ResNet50\n",
      "Epoch 1/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 7s/step - accuracy: 0.7974 - loss: 0.4113 - val_accuracy: 0.5475 - val_loss: 0.8015\n",
      "Epoch 2/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 5s/step - accuracy: 0.8797 - loss: 0.2553 - val_accuracy: 0.5475 - val_loss: 0.8548\n",
      "Epoch 3/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 5s/step - accuracy: 0.9044 - loss: 0.2053 - val_accuracy: 0.5551 - val_loss: 0.6972\n",
      "Epoch 4/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 5s/step - accuracy: 0.9295 - loss: 0.1775 - val_accuracy: 0.7072 - val_loss: 0.6296\n",
      "Epoch 5/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 5s/step - accuracy: 0.9459 - loss: 0.1511 - val_accuracy: 0.6806 - val_loss: 0.6696\n",
      "Training VGG16\n",
      "Epoch 1/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 10s/step - accuracy: 0.6852 - loss: 0.5575 - val_accuracy: 0.7795 - val_loss: 0.4559\n",
      "Epoch 2/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1463s\u001b[0m 10s/step - accuracy: 0.8235 - loss: 0.3740 - val_accuracy: 0.8023 - val_loss: 0.4380\n",
      "Epoch 3/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1902s\u001b[0m 13s/step - accuracy: 0.8193 - loss: 0.3838 - val_accuracy: 0.8327 - val_loss: 0.3723\n",
      "Epoch 4/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2152s\u001b[0m 14s/step - accuracy: 0.8456 - loss: 0.3379 - val_accuracy: 0.7414 - val_loss: 0.5032\n",
      "Epoch 5/5\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1806s\u001b[0m 12s/step - accuracy: 0.8426 - loss: 0.3567 - val_accuracy: 0.8327 - val_loss: 0.3641\n"
     ]
    }
   ],
   "source": [
    "#Training the modes\n",
    "\n",
    "# Train MobileNetV2\n",
    "print(\"Training MobileNetV2\")\n",
    "base_mnv2.trainable = True \n",
    "model_mnv2.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mnv2 = model_mnv2.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=5  \n",
    ")\n",
    "\n",
    "\n",
    "# Train ResNet50\n",
    "print(\"Training ResNet50\")\n",
    "base_resnet.trainable = True\n",
    "model_resnet.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                     loss='binary_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Train VGG16\n",
    "print(\"Training VGG16\")\n",
    "base_vgg.trainable = True\n",
    "model_vgg.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "history_vgg = model_vgg.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c9431-2a05-4ae5-8fdc-7694f3260489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using a simple (unweighted) average ensemble\n",
    "ensemble_preds = (preds_mnv2 + preds_resnet + preds_vgg) / 3.0\n",
    "\n",
    "# Convert probabilities to binary predictions using a threshold of 0.5\n",
    "ensemble_binary = (ensemble_preds > 0.5).astype(int)\n",
    "\n",
    "# Retrieve the true labels from the test generator\n",
    "true_labels = test_gen.labels\n",
    "\n",
    "# Compute ensemble accuracy\n",
    "ensemble_accuracy = accuracy_score(true_labels, ensemble_binary)\n",
    "print(\"Ensemble Test Accuracy (Simple Average):\", ensemble_accuracy)\n",
    "\n",
    "# Optionally, inspect a few sample ensemble predictions (probabilities)\n",
    "print(\"Sample Ensemble Predictions (first 5):\", ensemble_preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad076a98-afcb-4cd2-af60-3ba972b689ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mnv2.save('skin_cancer_mnv2.h5')\n",
    "model_resnet.save('skin_cancer_resnet50.h5')\n",
    "model_vgg.save('skin_cancer_vgg16.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228cf9c7-4ed6-42e1-92c0-dbe9b004179e",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b28e89c4-3e3a-49ad-93be-4e06ea3302eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 660 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nandi\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 528ms/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 2s/step\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the test directory path\n",
    "test_dir = 'test'  \n",
    "\n",
    "# Create a test ImageDataGenerator that only rescales the images\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load test data from directory\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256, 256),  # Use the same target size as during training\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important: keep order for accurate label matching\n",
    ")\n",
    "\n",
    "# Get predictions from each trained model on the test set\n",
    "preds_mnv2 = model_mnv2.predict(test_gen)\n",
    "preds_resnet = model_resnet.predict(test_gen)\n",
    "preds_vgg = model_vgg.predict(test_gen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
